model,dataset,bleu_score,rouge1,rouge2,rougeL,accuracy,hallucination_rate,hallucination_type,severity,context_length,response_length,contains_factual_error,contains_irrelevant_info,contains_fabrication
GPT-4,CNN/DailyMail,0.45,0.52,0.38,0.48,0.85,0.12,Extrinsic,Low,512,150,False,False,False
GPT-4,XSum,0.42,0.50,0.36,0.45,0.82,0.15,Extrinsic,Medium,256,100,True,False,True
GPT-3.5,CNN/DailyMail,0.38,0.45,0.32,0.42,0.80,0.18,Intrinsic,High,512,200,True,True,False
GPT-3.5,XSum,0.35,0.42,0.30,0.40,0.78,0.22,Intrinsic,Medium,256,120,False,True,False
Llama-2,CNN/DailyMail,0.40,0.47,0.35,0.44,0.81,0.16,Extrinsic,High,512,180,True,False,True
Llama-2,XSum,0.37,0.44,0.33,0.42,0.79,0.20,Intrinsic,Low,256,90,False,True,True
Claude,CNN/DailyMail,0.43,0.50,0.37,0.46,0.83,0.14,Intrinsic,Low,512,160,False,False,False
Claude,XSum,0.41,0.48,0.35,0.44,0.81,0.17,Extrinsic,Medium,256,110,True,True,False
Mistral,CNN/DailyMail,0.39,0.46,0.34,0.43,0.80,0.19,Intrinsic,High,512,170,True,False,True
Mistral,XSum,0.36,0.43,0.31,0.41,0.78,0.21,Extrinsic,Low,256,130,False,True,False
GPT-4,CNN/DailyMail,0.44,0.51,0.37,0.47,0.84,0.13,Intrinsic,Medium,512,145,False,True,False
GPT-4,XSum,0.43,0.49,0.36,0.46,0.83,0.14,Extrinsic,Low,256,95,True,False,True
GPT-3.5,CNN/DailyMail,0.37,0.44,0.31,0.41,0.79,0.19,Extrinsic,High,512,195,True,True,False
GPT-3.5,XSum,0.34,0.41,0.29,0.39,0.77,0.23,Intrinsic,Medium,256,125,False,True,True
Llama-2,CNN/DailyMail,0.39,0.46,0.34,0.43,0.80,0.17,Intrinsic,Low,512,175,True,False,True
Llama-2,XSum,0.36,0.43,0.32,0.41,0.78,0.21,Extrinsic,High,256,85,False,True,False
Claude,CNN/DailyMail,0.42,0.49,0.36,0.45,0.82,0.15,Extrinsic,Medium,512,165,False,False,False
Claude,XSum,0.40,0.47,0.34,0.43,0.80,0.18,Intrinsic,Low,256,115,True,True,True
Mistral,CNN/DailyMail,0.38,0.45,0.33,0.42,0.79,0.20,Intrinsic,High,512,180,True,False,True
Mistral,XSum,0.35,0.42,0.30,0.40,0.77,0.22,Extrinsic,Medium,256,140,False,True,False
